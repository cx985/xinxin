---
icon: SpringCloud
order: 11
date: 2024-03-27
category:
  - 消息队列
tag:
  - 消息队列

---

# kafka

## 1. kafka消息堆积了如何处理？

- 产生原因
  - 生产者产生的消息速率超过消费者消费速率时
- 解决方案
  1. 监控与警报
     - 设置实时监控系统，密切关注kafka集群的各项指标，包括但不限于broker磁盘使用率，消息堆积数量
     - 设置阈值警报，当消息堆积量达到一定水平立刻通知运维团队
  2. 增加消费者资源
     - 增加消费者数量
     - 优化消费者配置：如增大fetch.message.max.bytes参数，允许消费者一次性从Broker拉取更多消息，提高消费吞吐量；调整max.poll.records以控制每次拉取消息的数量
  3. 扩展现有的topic分区

## 2. kafka 如何保证消息不丢失？

- 生产者丢失消息的情况

  - send后添加回调函数

    ```java
            ListenableFuture<SendResult<String, Object>> future = kafkaTemplate.send(topic, o);
            future.addCallback(result -> logger.info("生产者成功发送消息到topic:{} partition:{}的消息", result.getRecordMetadata().topic(), result.getRecordMetadata().partition()),
                    ex -> logger.error("生产者发送消失败，原因：{}", ex.getMessage()));
    
    ```

    如果消息发送失败，需检查失败的原因

  - 另外生产者的重试次数设置一个比较合理的值，一般是3

- 消费者丢失消息的情况

  - 偏移量表示当前消费到的分区的所在位置
  - 解决方法：每次在真正消费完消息之后再自己手动提交offset

- kafka丢失的情况

  - kafka为分区引入了多副本机制。分区中的多个副本之间会有一个leader的家伙，其他副本称为follower。我们发送的消息会被发送到leader副本，然后follower副本才能从leader副本中拉取消息进行同步
  - 设置acks = all
    - acks的默认值为1, 代表我们的消息被leader副本接收之后就算被成功发送。当配置acks = all 表示只有所有ISR列表的副本全部收到消息时，生产者才会接收到来自服务器的响应，这种模式是最高级别的，也是最安全的，可以保证不止一个broker接收到消息，该模式的延迟会很高
  - 设置replication.factor >= 3

## 3. kafka 如何保证消息顺序消费？

- kafka只能保证分区中的消息有序
  - 消息在被追加到分区的时候都会分配一个特定的偏移量（offset）, kafka通过偏移量来保证消息在分区内的顺序性

- 解决方案
  - 方法1：1个Topic只对应一个分区。但是破坏了kafka的设计初衷
  - 方法2： 发送消息的时候指定key/Partition

## 4. kafka 如何保证消息不重复消费？

- kafka出现消息重复消费的原因
  - 服务端侧已经消费的数据没有成功提交offset (根本原因)
  - kafka侧 由于服务端处理业务时间长或者网络链接等原因让kafka认为服务假死，触发了分区rebalance
- 解决方案
  - 消费消息服务做幂等校验，比如redis的set,mysql的主键等天然的幂等功能。这种方法最有效
  - 关闭自动提交，将enable.auto.commit 参数设置为false, 关闭自动提交，开发者在代码中手动提交offset。 什么时候提交offset合适？
    - 处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样
    - 拉取到消息即提交： 会有消息丢失的风险，允许消息延时的场景，一般会采用这种方式。然后，通过定时任务在业务不繁忙的时候做数据兜底

## 5. kafka重试机制

Kafka 消费者在默认配置下会进行最多 10 次 的重试，每次重试的时间间隔为 0，即立即进行重试。如果在 10 次重试后仍然无法成功消费消息，则不再进行重试，消息将被视为消费失败
