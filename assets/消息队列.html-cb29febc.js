import{_ as a}from"./plugin-vue_export-helper-c27b6911.js";import{o as n,c as s,e as t}from"./app-57970fd2.js";const l={},e=t(`<h1 id="kafka" tabindex="-1"><a class="header-anchor" href="#kafka" aria-hidden="true">#</a> kafka</h1><h2 id="_1-kafka消息堆积了如何处理" tabindex="-1"><a class="header-anchor" href="#_1-kafka消息堆积了如何处理" aria-hidden="true">#</a> 1. kafka消息堆积了如何处理？</h2><ul><li>产生原因 <ul><li>生产者产生的消息速率超过消费者消费速率时</li></ul></li><li>解决方案 <ol><li>监控与警报 <ul><li>设置实时监控系统，密切关注kafka集群的各项指标，包括但不限于broker磁盘使用率，消息堆积数量</li><li>设置阈值警报，当消息堆积量达到一定水平立刻通知运维团队</li></ul></li><li>增加消费者资源 <ul><li>增加消费者数量</li><li>优化消费者配置：如增大fetch.message.max.bytes参数，允许消费者一次性从Broker拉取更多消息，提高消费吞吐量；调整max.poll.records以控制每次拉取消息的数量</li></ul></li><li>扩展现有的topic分区</li></ol></li></ul><h2 id="_2-kafka-如何保证消息不丢失" tabindex="-1"><a class="header-anchor" href="#_2-kafka-如何保证消息不丢失" aria-hidden="true">#</a> 2. kafka 如何保证消息不丢失？</h2><ul><li><p>生产者丢失消息的情况</p><ul><li><p>send后添加回调函数</p><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code>        <span class="token class-name">ListenableFuture</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">SendResult</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Object</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> future <span class="token operator">=</span> kafkaTemplate<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> o<span class="token punctuation">)</span><span class="token punctuation">;</span>
        future<span class="token punctuation">.</span><span class="token function">addCallback</span><span class="token punctuation">(</span>result <span class="token operator">-&gt;</span> logger<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">&quot;生产者成功发送消息到topic:{} partition:{}的消息&quot;</span><span class="token punctuation">,</span> result<span class="token punctuation">.</span><span class="token function">getRecordMetadata</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">topic</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> result<span class="token punctuation">.</span><span class="token function">getRecordMetadata</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                ex <span class="token operator">-&gt;</span> logger<span class="token punctuation">.</span><span class="token function">error</span><span class="token punctuation">(</span><span class="token string">&quot;生产者发送消失败，原因：{}&quot;</span><span class="token punctuation">,</span> ex<span class="token punctuation">.</span><span class="token function">getMessage</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果消息发送失败，需检查失败的原因</p></li><li><p>另外生产者的重试次数设置一个比较合理的值，一般是3</p></li></ul></li><li><p>消费者丢失消息的情况</p><ul><li>偏移量表示当前消费到的分区的所在位置</li><li>解决方法：每次在真正消费完消息之后再自己手动提交offset</li></ul></li><li><p>kafka丢失的情况</p><ul><li>kafka为分区引入了多副本机制。分区中的多个副本之间会有一个leader的家伙，其他副本称为follower。我们发送的消息会被发送到leader副本，然后follower副本才能从leader副本中拉取消息进行同步</li><li>设置acks = all <ul><li>acks的默认值为1, 代表我们的消息被leader副本接收之后就算被成功发送。当配置acks = all 表示只有所有ISR列表的副本全部收到消息时，生产者才会接收到来自服务器的响应，这种模式是最高级别的，也是最安全的，可以保证不止一个broker接收到消息，该模式的延迟会很高</li></ul></li><li>设置replication.factor &gt;= 3</li></ul></li></ul><h2 id="_3-kafka-如何保证消息顺序消费" tabindex="-1"><a class="header-anchor" href="#_3-kafka-如何保证消息顺序消费" aria-hidden="true">#</a> 3. kafka 如何保证消息顺序消费？</h2><ul><li><p>kafka只能保证分区中的消息有序</p><ul><li>消息在被追加到分区的时候都会分配一个特定的偏移量（offset）, kafka通过偏移量来保证消息在分区内的顺序性</li></ul></li><li><p>解决方案</p><ul><li>方法1：1个Topic只对应一个分区。但是破坏了kafka的设计初衷</li><li>方法2： 发送消息的时候指定key/Partition</li></ul></li></ul><h2 id="_4-kafka-如何保证消息不重复消费" tabindex="-1"><a class="header-anchor" href="#_4-kafka-如何保证消息不重复消费" aria-hidden="true">#</a> 4. kafka 如何保证消息不重复消费？</h2><ul><li>kafka出现消息重复消费的原因 <ul><li>服务端侧已经消费的数据没有成功提交offset (根本原因)</li><li>kafka侧 由于服务端处理业务时间长或者网络链接等原因让kafka认为服务假死，触发了分区rebalance</li></ul></li><li>解决方案 <ul><li>消费消息服务做幂等校验，比如redis的set,mysql的主键等天然的幂等功能。这种方法最有效</li><li>关闭自动提交，将enable.auto.commit 参数设置为false, 关闭自动提交，开发者在代码中手动提交offset。 什么时候提交offset合适？ <ul><li>处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样</li><li>拉取到消息即提交： 会有消息丢失的风险，允许消息延时的场景，一般会采用这种方式。然后，通过定时任务在业务不繁忙的时候做数据兜底</li></ul></li></ul></li></ul><h2 id="_5-kafka重试机制" tabindex="-1"><a class="header-anchor" href="#_5-kafka重试机制" aria-hidden="true">#</a> 5. kafka重试机制</h2><p>Kafka 消费者在默认配置下会进行最多 10 次 的重试，每次重试的时间间隔为 0，即立即进行重试。如果在 10 次重试后仍然无法成功消费消息，则不再进行重试，消息将被视为消费失败</p>`,11),p=[e];function i(o,c){return n(),s("div",null,p)}const r=a(l,[["render",i],["__file","消息队列.html.vue"]]);export{r as default};
